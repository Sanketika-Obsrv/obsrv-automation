#coredb
kafka:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 1
      memory: 2048Mi
    requests:
      cpu: 750m
      memory: 1024Mi
  persistence:
    existingClaim: "druid-pvc"
  zookeeper:
    resources:
      limits:
        cpu: 256m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 8Gi
      existingClaim: "druid-pvc"
  metrics:
    kafka:
      resources:
      limits:
        cpu: 100m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi
    jmx:
      resources:
      limits:
        cpu: 100m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi

postgresql:
  primary:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 250m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 10Gi
      mountPath: /bitnami/postgresql
      labels:
        system.storage: "true"
        system.ingestion: "true"
        system.querying: "true"
        system.api: "true"
      existingClaim: "druid-pvc"
  readReplicas:
    resources:
      limits:
        cpu: 250m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 8Gi
      mountPath: /bitnami/postgresql
      labels:
        system.storage: "true"
        system.ingestion: "true"
        system.querying: "true"
        system.api: "true"

valkey-denorm:
  primary:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 0.5
        memory: 2Gi
      requests:
        cpu: 0.5
        memory: 1Gi
    extraFlags:
      - --maxmemory 1024mb
      - --maxmemory-policy volatile-ttl
    # sidecars:
    #   resources:
    #     limits:
    #       cpu: 0.2
    #       memory: 100Mi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 2Gi
      existingClaim: "druid-pvc"
  replica:
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 2Gi
      existingClaim: "druid-pvc"

valkey-dedup:
  primary:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 0.5
        memory: 512Mi
      requests:
        cpu: 0.5
        memory: 512Mi
    extraFlags:
      - --maxmemory 512mb
      - --maxmemory-policy volatile-ttl
    # sidecars:
    #   resources:
    #     limits:
    #       cpu: 0.2
    #       memory: 100Mi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 2Gi
      existingClaim: "druid-pvc"
  replica:
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 2Gi
      existingClaim: "druid-pvc"

kong:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 100m
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 128Mi

druid-operator:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

#migrations
postgresql-migration:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 500m
      memory: 1024Mi
    requests:
      cpu: 250m
      memory: 768Mi
      #issue running helm templete

cert-manager:
  nodeSelector:
    envprod: obsrv
  resources:
    requests:
      cpu: 0.05
      memory: 100Mi
    limits:
      cpu: 0.05
      memory: 100Mi
  webhook:
    resources:
      requests:
        cpu: 0.05
        memory: 100Mi
      limits:
        cpu: 0.05
        memory: 100Mi
  cainjector:
    resources:
      requests:
        cpu: 0.05
        memory: 100Mi
      limits:
        cpu: 0.05
        memory: 100Mi

#coreinfra
promtail:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 200m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  sidecar:
    configReloader:
      resources:
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 100m
          memory: 128Mi

loki:
  singleBinary:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 0.5
        memory: 1024Mi
      requests:
        cpu: 0.5
        memory: 128Mi
    persistence:
      enableStatefulSetAutoDeletePVC: true
      size: 5Gi
      storageClass: null
      selector: null
      existingClaim: "druid-pvc"
  minio:
    resources:
      limits:
        cpu: 0.1
        memory: 256Mi
      requests:
        cpu: 0.1
        memory: 128Mi
    persistence:
      size: 5Gi
  monitoring:
    lokiCanary:
      resources:
        limits:
          cpu: 0.1
          memory: 256Mi
        requests:
          cpu: 0.1
          memory: 128Mi
  gateway:
    resources:
      limits:
        cpu: 0.1
        memory: 256Mi
      requests:
        cpu: 0.1
        memory: 128Mi
  read:
    replicas: 1
    resources:
      limits:
        cpu: 512m
        memory: 1024Mi
      requests:
        cpu: 256m
        memory: 512Mi
    persistence:
      # -- Enable StatefulSetAutoDeletePVC feature
      enableStatefulSetAutoDeletePVC: true
      # -- Size of persistent disk
      size: 5Gi
      storageClass: null
      selector: null
  write:
    replicas: 1
    resources:
      limits:
        cpu: 512m
        memory: 1024Mi
      requests:
        cpu: 256m
        memory: 512Mi
      persistence:
        # -- Enable volume claims in pod spec
        volumeClaimsEnabled: true
        # -- Parameters used for the `data` volume when volumeClaimEnabled if false
        dataVolumeParameters:
          emptyDir: {}
        # -- Enable StatefulSetAutoDeletePVC feature
        enableStatefulSetAutoDeletePVC: false
        # -- Size of persistent disk
        size: 5Gi
        storageClass: null
        selector: null
  backend:
    persistence:
      volumeClaimsEnabled: true
      dataVolumeParameters:
        emptyDir: {}
      enableStatefulSetAutoDeletePVC: false
      size: 10Gi
      storageClass: null
      selector: null




#druid-raw-cluster need changes in yaml files
druid-raw-cluster:
  druid_brokers:
    resources:
      limits:
        cpu: 500m
        memory: 750Mi
      requests:
        cpu: 250m
        memory: 128Mi

  druid_coordinator:
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 500Mi

  druid_overlord:
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi

  druid_historical:
    resources:
      limits:
        cpu: 1
        memory: 3700Mi
      requests:
        cpu: 800m
        memory: 3000Mi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 50Gi
      existingClaim: "druid-pvc"

  druid_middlemanager:
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 1Gi

  druid_indexer:
    resources:
      limits:
        cpu: 1
        memory: 11Gi
      requests:
        cpu: 1
        memory: 10Gi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 20Gi
      existingClaim: "druid-pvc"

  druid_router:
    resources:
      limits:
        cpu: 512m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi

  zookeeper:
    # nodeSelector:
    #   envprod: obsrv
    resources:
      limits:
        cpu: 256m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
    persistence:
      accessModes:
        - ReadWriteOnce
      size: 1Gi
      existingClaim: "druid-pvc"

flink:
  nodeSelector:
    envprod: obsrv
  flink_resource: &flink_resources
    taskmanager:
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
        limits:
          cpu: 1
          memory: 1024Mi
    jobmanager:
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
        limits:
          cpu: 1
          memory: 1024Mi
  flink_jobs:
    unified-pipeline:
      resources: *flink_resources
    transformer-ext:
      resources: *flink_resources
    master-data-processor-ext:
    resources: *flink_resources
    cache-indexer:
        resources: *flink_resources

kafka-message-exporter:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

kube-prometheus-stack:
  alertmanager:
    nodeSelector:
      envprod: obsrv
    alertmanagerSpec:
      resources:
        limits:
          cpu: "0.1"
          memory: 256Mi
        requests:
          cpu: "0.1"
          memory: 128Mi
  prometheusOperator:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 0.1
        memory: 512Mi
      requests:
        cpu: 0.1
        memory: 128Mi
    prometheusConfigReloader:
      resources:
        limits:
          cpu: 0.1
          memory: 256Mi
        requests:
          cpu: 0.1
          memory: 128Mi
  prometheus:
    server:
      resources:
        limits:
          cpu: 0.5
          memory: 512Mi
        requests:
          cpu: 0.5
          memory: 512Mi
          #issue getting resources
  grafana:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 0.2
        memory: 1024Mi
      requests:
        cpu: 0.1
        memory: 500Mi
    persistence:
      type: pvc
      # storageClassName: default
      accessModes:
        - ReadWriteOnce
      size: 10Gi
      # annotations: {}
      finalizers:
        - kubernetes.io/pvc-protection

  kube-state-metrics:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 0.1
        memory: 256Mi
      requests:
        cpu: 0.1
        memory: 128Mi

  prometheus-node-exporter:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 100m
        memory: 64Mi
      requests:
        cpu: 100m
        memory: 32Mi

kubernetes-reflector:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

postgresql-exporter:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 50m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 128Mi

prometheus-pushgateway:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 50m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 128Mi



secor:
  resources:
    limits:
      cpu: 128m
      memory: 512Mi
    requests:
      cpu: 128m
      memory: 512Mi
  persistence:
    existingClaim: "druid-pvc"
  nodeSelector:
    envprod: obsrv

spark:
  master:
    resources:
      limits:
        cpu: 1
        memory: 2Gi
      requests:
        cpu: 1
        memory: 2Gi
    nodeSelector:
      envprod: obsrv
  worker:
    replicaCount: 1
    coreLimit: 10
    resources:
      limits:
        cpu: 8
        memory: 30Gi
      requests:
        cpu: 4
        memory: 15Gi
    nodeSelector:
      envprod: obsrv

  persistence:
    enabled: true
    master:
      existingClaim: "druid-pvc"
    worker:
      existingClaim: "druid-pvc"
    # masterTmp:
    #   name: spark-master-tmp
    #   # storageClassName: gp2
    #   storage:
    #     size: 2Gi
    # workerTmp:
    #   name: spark-worker-tmp
    #   # storageClassName: gp2
    #   storage:
    #     size: 2Gi
    # masterMetadata:
    #   name: spark-master-metadata
    #   # storageClassName: gp2
    #   storage:
    #     size: 2Gi
    # workerMetadata:
    #   name: spark-worker-metadata
    #   # storageClassName: gp2
    #   storage:
    #     size: 2Gi

superset:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 512m
      memory: 1024Mi
    requests:
      cpu: 250m
      memory: 512Mi

#obsrvtools
command-api:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 0.1
      memory: 128Mi
    requests:
      cpu: 0.1
      memory: 128Mi

dataset-api:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 0.5
      memory: 2048Mi
    requests:
      cpu: 0.5
      memory: 1024Mi

config-api:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 0.5
      memory: 1024Mi
    requests:
      cpu: 0.5
      memory: 512Mi

web-console:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 0.5
      memory: 1024Mi
    requests:
      cpu: 0.5
      memory: 512Mi

#additional
druid-exporter:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

velero:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 0.1
      memory: 1024Mi
    requests:
      cpu: 0.1
      memory: 500Mi
  nodeAgent:
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 1024Mi

volume-autoscaler:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 0.05
      memory: 100Mi
    requests:
      cpu: 0.05
      memory: 100Mi

lakehouse-connector:
  nodeSelector:
    envprod: obsrv
  jobmanager:
    cpu_requests: 1
    cpu_limits: 1
    memory_requests: 1024Mi
    memory_limits: 1024Mi

  taskmanager:
    cpu_requests: 1
    cpu_limits: 1
    memory_requests: 1024Mi
    memory_limits: 2300Mi

trino:
  coordinator:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 1
        memory: 2048Mi
      requests:
        cpu: 1
        memory: 2048Mi
  worker:
    nodeSelector:
      envprod: obsrv
    resources:
      limits:
        cpu: 1
        memory: 2048Mi
      requests:
        cpu: 1
        memory: 2048Mi

s3-exporter:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 50m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 128Mi

hms:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 100m
      memory: 1024Mi
    requests:
      cpu: 100m
      memory: 1024Mi

opentelemetry-collector:
  resources:
    limits:
      cpu: 250m
      memory: 512Mi
    requests:
      cpu: 250m
      memory: 512Mi

keycloak:
  nodeSelector:
    envprod: obsrv
  resources:
    limits:
      cpu: 750m
      memory: 750Mi
    requests:
      cpu: 250m
      memory: 512Mi

redis-exporter:
  nodeSelector:
    envprod: obsrv
  resources:
      limits:
        cpu: 250m
        memory: 512Mi
      requests:
        cpu: 250m
        memory: 256Mi

minio:
  nodeSelector:
    envprod: obsrv
  resourcesPreset: "nano"
  resources: {}
  persistence:
    size: 8Gi
    storageClass: null
    selector: null
    existingClaim: "druid-pvc"