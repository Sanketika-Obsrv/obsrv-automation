env = "{{ .Values.global.env }}"
spark.master= "local[*]"

kafka {
  producer = {
    broker-servers =  "{{ .Values.global.kafka.host }}:{{ .Values.global.kafka.port }}"
    compression = "snappy"
    max-request-size = 1000000 # 1MB
  }
  output = {
    connector = {
      failed.topic = "{{ .Values.global.kafka.connectorsFailedTopic }}"
      metric.topic = "{{ .Values.global.kafka.connectorsMetricTopic }}"
    }
  }
}

#dataset-registry config
postgres {
  host = "{{ .Values.global.postgresql.host }}"
  port = "{{ .Values.global.postgresql.port }}"
  maxConnections = 2
  user = "{{ .Values.postgresqlUser | default .Values.global.postgresql.obsrv.user }}"
  password = "{{ .Values.postgresqlPassword | default .Values.global.postgresql.obsrv.password }}"
  database = "{{ .Values.postgresqlDatabase | default .Values.global.postgresql.obsrv.name }}"
}

obsrv.encryption.key = "{{ .Values.global.encryption_key }}"