global:
  sanketika_docker_registry: &sanketika_docker_registry "docker.io/sanketikahub"
  docker_registry_secret_name: &docker_registry_secret_name "docker-registry-secret"
  image:
    imagePullSecrets: *docker_registry_secret_name
  dockerconfigjson: ""
  azure:
    images:
      command_api:
        # tag: 1.0.2-GA
        digest: 1.0.2
        image: flink-command-service
        registry: *sanketika_docker_registry
      dataset_api:
        # tag:1.3.1
        digest: 1.0.2-GA
        image: obsrv-api-service
        registry: *sanketika_docker_registry
      druid_exporter:
        # tag: v0.11
        digest: v0.11
        image: druid-exporter
        registry: *sanketika_docker_registry
      druid_operator:
        # tag: 0.0.7
        digest: 0.0.7
        image: druid-operator
        registry: docker.io/druidio
      druid_raw_cluster:
        # tag: 28.0.1
        digest: 28.0.1
        image: druid
        registry: docker.io/apache
      zookeeper:
        # tag: 3.9.1
        digest: 3.9.1
        image: zookeeper
        registry: *sanketika_docker_registry
      # os_shell:
      #   # tag: 11-debian-11-r37
      #   digest: sha256:77bdba3135998baadc20015e00a9742eebac52167b90c3e46d0c339a2d668b12
      #   image: os-shell
      #   registry: docker.io/bitnami
      merged_pipeline:
        # tag: 1.0.2-GA
        digest: 1.0.3-GA
        image: merged-pipeline
        registry: *sanketika_docker_registry
      master_data_processor:
        # tag: 1.0.2-GA
        digest: 1.0.3-GA
        image: master-data-processor
        registry: *sanketika_docker_registry
      kafka:
        # tag: 3.6.0
        digest: 3.6.0
        image: kafka
        registry: *sanketika_docker_registry
      # autodiscovery:
      #   # tag: 1.25.12-debian-11-r26
      #   digest: sha256:9774c3452853d3ba9c4744d0acfa36d63f9d87ba7e43fd292caf7dae9115fac4
      #   image: kubectl
      #   registry: docker.io/bitnami
      kafka_exporter:
        # tag: 1.0.1
        digest: 1.0.1
        image: kafka-exporter
        registry: *sanketika_docker_registry
      jmx_exporter:
        # tag: 1.0.0
        digest: 1.0.0
        image: jmx-exporter
        registry: *sanketika_docker_registry
      # bitnami_shell:
      #   # tag: 11-debian-11-r136
      #   digest: sha256:0aa4e2314721a29fa2a8ea0ed901e2db2842c4217fc60ed5700ee62dbcd0fcbc
      #   image: bitnami-shell
      #   registry: docker.io/bitnami
      # postgresql:
      #   # tag: 14.9.0-debian-11-r2
      #   digest: sha256:f349e5f081c5894c80321fbb22981c00e22f802055d2ac34a3b9260e0be6df44
      #   image: postgresql
      #   registry: docker.io/bitnami
      postgres:
        # tag: 15.4-alpine
        digest: 16.1.0-debian-11-r19
        image: postgresql
        registry: docker.io/bitnami
        # registry: docker.io
      postgresql_exporter:
        # tag: 1.0.1
        digest: 1.0.1
        image: postgres-exporter
        registry: *sanketika_docker_registry
      # redis:
      #   digest: sha256:017aaf627b7e115f6fb036c6e3360a0de4d83f1d62b315db31e89a0c09a4698e
      #   image: redis
      #   registry: docker.io/bitnami
      # using redis alpine image
      redis:
        # tag: 7.2.2-alpine
        digest: 7.2.2-alpine
        image: redis
        registry: *sanketika_docker_registry
      # redis_sentinel:
      #   digest: sha256:a0317520a0275f1937a280fec73748b7a7995c17e137dab58b38e4b1fb4dfc15
      #   image: redis-sentinel
      #   registry: docker.io/bitnami
      redis_exporter:
        # tag: 1.0.0
        digest: 1.0.0
        image: redis-exporter
        registry: *sanketika_docker_registry
      secor:
        # tag: 0.30-jdk-11-azure
        digest: 1.0.0-GA
        image: secor
        registry: *sanketika_docker_registry
      ubuntu:
        # tag: 20.04
        digest: 20.04
        image: ubuntu
        registry: docker.io/library
      k8s_sidecar:
        # tag: 1.25.2
        digest: 1.25.2
        image: k8s-sidecar
        #registry: quay.io/kiwigrid
        registry: *sanketika_docker_registry
      grafana_image_renderer:
        # tag: 3.11.1
        digest: 3.11.1
        image: grafana-image-renderer
        registry: *sanketika_docker_registry
      curl:
        # tag: 8.4.0
        digest: 8.4.0
        image: curl
        #registry: docker.io/alpine
        registry: *sanketika_docker_registry
      busybox:
        # tag: 1.31.1
        digest: 1.31.1
        image: busybox
        registry: docker.io/library
      grafana:
        # tag: 9.5.2
        digest: 9.5.2
        image: grafana
        registry: docker.io/grafana
      node_exporter:
        # tag: master
        digest: master
        image: node-exporter
        registry: docker.io/prom
      alertmanager:
        # tag: main_v1.0.1
        digest: main_v1.0.1
        image: alertmanager
        registry: *sanketika_docker_registry
      prometheus_operator:
        # tag: v0.66.0
        digest: v0.66.0
        image: prometheus-operator
        registry: *sanketika_docker_registry
      prometheus_config_reloader:
        digest: v0.60.1
        image: prometheus-config-reloader
        registry: quay.io/prometheus-operator
      # thanos:
      #   digest: sha256:e7d337d6ac2aea3f0f9314ec9830291789e16e2b480b9d353be02d05ce7f2a7e
      #   image: thanos
      #   registry: quay.io/thanos
      prometheus:
        # tag: main
        digest: main
        image: prometheus
        registry: docker.io/prom
      kube_state_metrics:
        # digest: sha256:ec5732e28f151de3847df60f48c5a570aacdb692ff1ce949d97105ae5e5a6722
        digest: v2.8.2
        image: kube-state-metrics
        registry: registry.k8s.io/kube-state-metrics
      alpine:
        # tag:3.16
        digest: 3.16
        image: alpine
        registry: docker.io/library
      kube_webhook_certgen:
        digest: sha256:543c40fd093964bc9ab509d3e791f9989963021f1e9e4c9c7b6700b02bfb227b
        image: kube-webhook-certgen
        registry: registry.k8s.io/ingress-nginx
      grafana_agent_operator:
        # tag: main
        digest: main
        image: agent-operator
        registry: *sanketika_docker_registry
      minio:
        # tag: 1.0.1
        digest: 1.0.1
        image: minio
        registry: *sanketika_docker_registry
      # kubectl_image:
      #   digest: sha256:9774c3452853d3ba9c4744d0acfa36d63f9d87ba7e43fd292caf7dae9115fac4
      #   image: kubectl
      #   registry: docker.io/bitnami
      kubectl_image:
        # tag: 1.0.0
        digest: 1.0.0
        image: kubectl
        registry: *sanketika_docker_registry
      mc_image:
        # tag: 1.0.0
        digest: 1.0.0
        image: minio-client
        registry: *sanketika_docker_registry
      # enterprise_logs:
      #   digest: sha256:469d8fdb73288d7a3e243c74856f155f8c498c9710102c338758ba431b235ef9
      #   image: enterprise-logs
      #   registry: docker.io/grafana
      # enterprise_logs_provisioner:
      #   digest: sha256:1e1e6da087fadee34fe7c1224da80bd6011e7841927bc73fde974bffba50fc54
      #   image: enterprise-logs-provisioner
      #   registry: docker.io/grafana
      loki_test:
        # latest
        digest: latest
        image: loki-helm-test
        registry: docker.io/grafana
      loki_canary:
        # tag: 1.0.0
        digest: 1.0.0
        image: loki-canary
        registry: *sanketika_docker_registry
      loki:
        # tag: 1.0.0
        digest: 1.0.0
        image: loki
        registry: *sanketika_docker_registry
      loki_gateway:
        # tag: 1.25-alpine-1
        digest: 1.25-alpine-1
        image: nginx-unprivileged
        registry: *sanketika_docker_registry
      promtail:
        # tag: main-2327789
        digest: main-2327789
        image: promtail
        registry: *sanketika_docker_registry
      web_console:
        # tag: 1.3.1
        digest: 1.0.2-GA
        image: obsrv-web-console
        registry: *sanketika_docker_registry
      # superset:
      #   # tag: 2.0.0
      #   digest: sha256:ca32ff641daca7447edfe78345e1abbc3b278895b1d4a245e69e28020e3310b7
      #   image: superset
      #   registry: docker.io/apache

  env: &global-env "dev"
  building_block: &global-bb "obsrv"
  # redis_host: &global-redis-host "obsrv-redis-master.redis.svc.cluster.local"
  # postgresql_host: &global-psql-host "obsrv-postgresql-hl.postgresql.svc.cluster.local"
  # postgresql_druid_url: &global-psql-druid-conn "jdbc:postgresql://obsrv-postgresql-hl.postgresql.svc.cluster.local:5432/druid_raw"
  druid_host: &global-druid-host "http://druid-raw-routers.druid-raw.svc.cluster.local"
  druid_URL: &global-druid-URL "http://druid-raw-routers.druid-raw.svc:8888"

  postgresql_obsrv_username: &psql-obsrv-user "obsrv"
  postgresql_obsrv_database: &psql-obsrv-db "obsrv"
  postgresql_obsrv_user_password: &psql-obsrv-pwd "obsrv123"
  postgresql_druid_user_password: &psql-druid-pwd "druidraw123"

  cloud-storage-provider: &global-cloud-storage-provider "s3"
  cloud-storage-region: &global-cloud-storage-region "us-east-2"

  s3_bucket: &global-s3-bucket ""
  s3_access_key: &global-s3-access-key ""
  s3_secret_key: &global-s3-secret-access-key ""
  region: &global-region ""
  s3_endpoint_url: &global-s3-endpoint-url ""
  s3_path_style_access: &global-s3-path-style-access "true"

  azure_storage_account_name: &global-azure-account-name ""
  azure_storage_account_key: &global-azure-account-key ""
  azure_storage_container: &global-azure-container ""

  gcs_bucket: &gcs-bucket ""

  druid_deepstorage_type: &global-druid-deep-store-type ""
  kubernetes_storage_class: &global-k9s-storage-class ""

  sys-events-kafka-topic: &sys-events-kafka-topic "dev.system.events"
  sys-telemetry-events-kafka-topic: &sys-telemetry-events-kafka-topic "dev.system.telemetry.events"

alert-rules:
  enabled: true
  namespace: monitoring

dataset-api:
  enabled: true
  namespace: dataset-api
  SYSTEM_ENV: *global-env
  druid_service:
    DRUID_HOST: *global-druid-host
    DRUID_PORT: 8888
  postgres_service:
    POSTGRES_PORT: 5432
    POSTGRES_DATABASE: *psql-obsrv-db
    POSTGRES_USERNAME: *psql-obsrv-user
    POSTGRES_PASSWORD: *psql-obsrv-pwd
  dockerhub: sanketikahub
  repository: obsrv-api-service
  image_tag: 1.0.1
  imagePullSecrets: ""
  dedup_redis_service:
    REDIS_PORT: 6379
  denorm_redis_service:
    REDIS_PORT: 6379
  exhaust_service:
    # LABEL_CONTAINER: *azure-container
    CLOUD_STORAGE_PROVIDER: &global-cloud-storage-provider ""
    CLOUD_STORAGE_REGION: &global-cloud-storage-region ""
    # CONTAINER: *azure-container
    CONTAINER_PREFIX: "telemetry-data"
  # service_account_annotations:
  #   meta.helm.sh/release-namespace: dataset-api

command-api:
  enabled: true
  namespace: command-api
  system_env: *global-env

druid-exporter:
  enabled: true
  namespace: druid-raw
  druidURL: *global-druid-URL
  serviceMonitor:
    enabled: true
    namespace: druid-raw
    interval: 30s
    scrapeTimeout: 10s

druid-operator:
  enabled: true
  namespace: druid-raw

druid-raw-cluster:
  enabled: true
  namespace: druid-raw
  # druid_namespace: druid-raw
  druid_metadata_storage_connector_user: druid_raw
  druid_metadata_storage_connector_password: *psql-druid-pwd
  # druid_metadata_storage_connector_connectURI: *global-psql-druid-conn
  druid_worker_capacity: 2
  druid_env: *global-env
  storageClass: *global-k9s-storage-class
  druid_deepstorage_type: *global-druid-deep-store-type
  druid_indexer_logs_type: *global-druid-deep-store-type
  # druid_indexer_logs_container: *azure-container
  s3_bucket: *global-s3-bucket
  s3_access_key: *global-s3-access-key
  s3_secret_key: *global-s3-secret-access-key
  s3_endpoint_url: *global-s3-endpoint-url
  s3_path_style_access: *global-s3-path-style-access

  # azure_storage_account_name: *azure-account-name
  # azure_storage_account_key: *azure-account-key
  # azure_storage_container: *azure-container
  gcs_bucket: *gcs-bucket
  zookeeper:
    namespace: druid-raw
  serviceAccount:
    create: false
    annotations:
      meta.helm.sh/release-namespace: druid-raw
      eks.amazonaws.com/role-arn: arn:aws:iam::725876873105:role/dev-obsrv-test-druid-raw-sa-iam-role
    name: druid-raw-sa

merged-pipeline:
  enabled: true
  name: merged-pipeline
  namespace: flink
  env: *global-env
  checkpoint_store_type: *global-cloud-storage-provider

master-data-processor:
  enabled: true
  name: master-data-processor
  namespace: flink
  env: *global-env
  checkpoint_store_type: *global-cloud-storage-provider

flink-sa:
  enabled: false
  namespace: flink
  serviceAccount:
    annotations:
      meta.helm.sh/release-namespace: flink
      eks.amazonaws.com/role-arn: arn:aws:iam::725876873105:role/dev-obsrv-test-flink-sa-iam-role
    name: flink-sa

grafana-configs:
  enabled: true
  namespace: monitoring

kafka:
  enabled: true
  namespace: kafka
  provisioning:
    enabled: true
    topics:
      - name: "dev.ingest"
        partitions: 1
        replicationFactor: 1
        config:
          max.message.bytes: "10000024"
      - name: "dev.masterdata.ingest"
        partitions: 1
        replicationFactor: 1
        config:
          max.message.bytes: "10000024"
  persistence:
    size: 50Gi
  zookeeper:
    persistence:
      size: 8Gi
    namespace: kafka
    fullnameOverride: kafka-zookeeper
  metrics:
    kafka:
      enabled: false
    jmx:
      enabled: false

kafka-exporter:
  enabled: true
  namespace: kafka
  prometheus:
    serviceMonitor:
      enabled: true
      namespace: kafka
      interval: "30s"
      additionalLabels:
        app: kafka-exporter
        release: monitoring

postgresql:
  enabled: true
  namespace: postgresql
  image:
    registry: docker.io
    repository: bitnami/postgresql
    tag: 16.1.0-debian-11-r19
  auth:
    enablePostgresUser: true
    postgresPassword: postgres
  primary:
    extendedConfiguration: |
      password_encryption = md5
    resources:
      limits: {}
      requests:
        memory: 256Mi
        cpu: 250m
    persistence:
      size: 1Gi
      enabled: true
      mountPath: /bitnami/postgresql

    initdb:
      user: postgres
      password: postgres
      scriptsConfigMap: ""
      scripts:
        00_create_superset_db.sql: |
          CREATE DATABASE superset;
        01_create_superset_user.sql: |
          CREATE USER superset WITH ENCRYPTED PASSWORD 'superset123';
          ALTER DATABASE superset OWNER TO superset;
          GRANT ALL PRIVILEGES ON DATABASE superset TO superset;
        02_create_druid_raw_db.sql: |
          CREATE DATABASE druid_raw;
        03_create_druid_raw_user.sql: |
          CREATE USER druid_raw WITH ENCRYPTED PASSWORD 'druidraw123';
          ALTER DATABASE druid_raw OWNER TO druid_raw;
          GRANT ALL PRIVILEGES ON DATABASE druid_raw TO druid_raw;
        04_create_obsrv_db.sql: |
          CREATE DATABASE obsrv;
        05_create_obsrv_user.sql: |
          CREATE USER obsrv WITH ENCRYPTED PASSWORD 'obsrv123';
          ALTER DATABASE obsrv OWNER TO obsrv;
          GRANT ALL PRIVILEGES ON DATABASE obsrv TO obsrv;
        06_create_tables.sql: |
          \c obsrv

          CREATE TABLE IF NOT EXISTS datasets (
              id TEXT PRIMARY KEY,
              dataset_id TEXT,
              type TEXT NOT NULL,
              name TEXT,
              validation_config JSON,
              extraction_config JSON,
              dedup_config JSON,
              data_schema JSON,
              denorm_config JSON,
              router_config JSON,
              dataset_config JSON,
              tags TEXT[],
              data_version INT,
              status TEXT,
              created_by TEXT,
              updated_by TEXT,
              created_date TIMESTAMP NOT NULL DEFAULT now(),
              updated_date TIMESTAMP NOT NULL,
              published_date TIMESTAMP NOT NULL DEFAULT now()
          );

          CREATE INDEX IF NOT EXISTS datasets_status ON datasets(status);

          CREATE TABLE IF NOT EXISTS datasources (
            id TEXT PRIMARY KEY,
            datasource text NOT NULL,
            dataset_id TEXT NOT NULL REFERENCES datasets (id),
            ingestion_spec json,
            lakehouse_spec json,
            datasource_ref text NOT NULL,
            retention_period json,
            archival_policy json,
            purge_policy json,
            backup_config json NOT NULL,
            metadata json,
            status text NOT NULL,
            created_by text NOT NULL,
            updated_by text NOT NULL,
            created_date TIMESTAMP NOT NULL DEFAULT now(),
            updated_date TIMESTAMP NOT NULL,
            published_date TIMESTAMP NOT NULL DEFAULT now(),
            UNIQUE (dataset_id, datasource)
          );

          CREATE INDEX IF NOT EXISTS datasources_dataset ON datasources(dataset_id);

          CREATE INDEX IF NOT EXISTS datasources_status ON datasources(status);

          CREATE TABLE IF NOT EXISTS dataset_transformations (
            id TEXT PRIMARY KEY,
            dataset_id TEXT NOT NULL REFERENCES datasets (id),
            field_key TEXT NOT NULL,
            transformation_function JSON,
            status TEXT NOT NULL,
            created_by TEXT NOT NULL,
            updated_by TEXT NOT NULL,
            created_date TIMESTAMP NOT NULL DEFAULT now(),
            updated_date TIMESTAMP NOT NULL,
            published_date TIMESTAMP NOT NULL DEFAULT now(),
            mode TEXT,
            metadata JSON,
            UNIQUE (dataset_id, field_key)
          );

          CREATE INDEX IF NOT EXISTS dataset_transformations_dataset ON dataset_transformations (dataset_id);

          CREATE INDEX IF NOT EXISTS dataset_transformations_status ON dataset_transformations (status);

          CREATE TABLE IF NOT EXISTS dataset_source_config (
            id TEXT PRIMARY KEY,
            dataset_id TEXT NOT NULL REFERENCES datasets (id),
            connector_type text NOT NULL,
            connector_config json NOT NULL,
            status text NOT NULL,
            connector_stats json,
            created_by text NOT NULL,
            updated_by text NOT NULL,
            created_date TIMESTAMP NOT NULL DEFAULT now(),
            updated_date TIMESTAMP NOT NULL,
            published_date TIMESTAMP NOT NULL,
            UNIQUE (dataset_id)
          );
          CREATE INDEX IF NOT EXISTS  dataset_source_config_dataset ON dataset_source_config(dataset_id);

          CREATE INDEX IF NOT EXISTS dataset_source_config_status ON dataset_source_config(status);

          GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO obsrv;

          GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO obsrv;

postgresql-exporter:
  enabled: true
  namespace: postgresql
  serviceMonitor:
    enabled: true
    namespace: postgresql
    interval: 30s
    labels:
      release: monitoring
      system.monitoring: "true"

redis-dedup:
  enabled: true
  namespace: redis
  commonLabels:
    system.storage: 'true'
    system.processing: 'true'
  image:
    registry: docker.io
    repository: bitnami/redis
    tag: 7.0.5-debian-11-r15
    digest: ""
    pullPolicy: IfNotPresent
    pullSecrets:
      - ""

  architecture: standalone
  commonConfiguration: |-
    # Enable RDB persistence
    save 300 100

  auth:
    enabled: false

  master:
    count: 1
    ## @param master.configuration Configuration for Redis&reg; master nodes
    ## ref: https://redis.io/topics/config
    ##
    configuration: ""
    podLabels:
      system.storage: 'true'
      system.processing: 'true'
    disableCommands:
      - FLUSHALL
    ## @param master.extraFlags Array with additional command line flags for Redis&reg; master
    ## e.g:
    extraFlags:
      - "--maxmemory 512mb"
      - "--maxmemory-policy volatile-ttl"
    containerPorts:
      redis: 6379
    resources:
      limits:
        cpu: 0.5
        memory: 512Mi
      requests:
        cpu: 0.5
        memory: 512Mi
    persistence:
      enabled: true
      labels:
        system.storage: 'true'
        system.processing: 'true'
      path: /data
      subPath: ""
      subPathExpr: ""
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 1Gi
    # sidecars:
    #   - name: redis-backup
    #     image: sanketikahub/redis-backup:0.5
    #     imagePullPolicy: IfNotPresent
    #     volumeMounts:
    #       - mountPath: /data
    #         name: redis-data
    #     env:
    #       - name: REDIS_BACKUP_CRON_SCHEDULE
    #         value: "00 00 * * *"
    #       - name: CLOUD_SERVICE
    #         value: azure
    #       - name: AZURE_BACKUP_BUCKET
    #         value: ""
    #       - name: S3_BACKUP_BUCKET
    #         value: ""
    #       - name: GCS_BACKUP_BUCKET
    #         value: ""
    #       - name: REDIS_RDB_FILE_PATH
    #         value: /data
    #       - name: REDIS_REPLICATION_MODE
    #         value: master
    #     resources:
    #       limits:
    #         cpu: 0.2
    #         memory: 100Mi
    serviceAccount:
      create: false
    #   name: ${redis_backup_service_account_name}
    #   annotations:
    #     ${redis_backup_sa_annotations}

  replica:
    replicaCount: 1
    ## @param replica.configuration Configuration for Redis&reg; replicas nodes
    ## ref: https://redis.io/topics/config
    ##
    configuration: ""
    disableCommands:
      - FLUSHALL
    ## @param replica.extraFlags Array with additional command line flags for Redis&reg; replicas
    ## e.g:
    extraFlags:
      - "--maxmemory 512mb"
      - "--maxmemory-policy volatile-ttl"
    ## @param replica.containerPorts.redis Container port to open on Redis&reg; replicas nodes
    ##
    containerPorts:
      redis: 6379
    persistence:
      enabled: true
      path: /data
      subPath: ""
      subPathExpr: ""
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 1Gi
    serviceAccount:
      create: false

redis-denorm:
  enabled: true
  namespace: redis
  commonLabels:
      system.storage: 'true'
      system.processing: 'true'
  image:
    registry: docker.io
    repository: bitnami/redis
    tag: 7.0.5-debian-11-r15
    digest: ""
    pullPolicy: IfNotPresent
    pullSecrets:
      - ""

  architecture: standalone
  commonConfiguration: |-
    # Enable RDB persistence
    save 300 100

  auth:
    enabled: false

  master:
    count: 1
    podLabels:
      system.storage: 'true'
      system.processing: 'true'
    ## @param master.configuration Configuration for Redis&reg; master nodes
    ## ref: https://redis.io/topics/config
    ##
    configuration: ""
    disableCommands:
      - FLUSHALL
    ## @param master.extraFlags Array with additional command line flags for Redis&reg; master
    ## e.g:
    extraFlags:
      - "--maxmemory 1024mb"
      - "--maxmemory-policy noeviction"
    containerPorts:
      redis: 6379
    resources:
      limits:
        cpu: 0.5
        memory: 2Gi
      requests:
        cpu: 0.5
        memory: 1Gi
    persistence:
      enabled: true
      labels:
        system.storage: 'true'
        system.processing: 'true'
      path: /data
      subPath: ""
      subPathExpr: ""
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 2Gi
    # sidecars:
    #   - name: redis-backup
    #     image: sanketikahub/redis-backup:0.5
    #     imagePullPolicy: IfNotPresent
    #     volumeMounts:
    #       - mountPath: /data
    #         name: redis-data
    #     env:
    #       - name: REDIS_BACKUP_CRON_SCHEDULE
    #         value: "00 00 * * *"
    #       - name: CLOUD_SERVICE
    #         value: azure
    #       - name: AZURE_BACKUP_BUCKET
    #         value: ""
    #       - name: S3_BACKUP_BUCKET
    #         value: ""
    #       - name: GCS_BACKUP_BUCKET
    #         value: ""
    #       - name: REDIS_RDB_FILE_PATH
    #         value: /data
    #       - name: REDIS_REPLICATION_MODE
    #         value: master
    #     resources:
    #       limits:
    #         cpu: 0.2
    #         memory: 100Mi
    serviceAccount:
      create: false
    #   name: ${redis_backup_service_account_name}
    #   annotations:
    #     ${redis_backup_sa_annotations}

  replica:
    replicaCount: 1
    ## @param replica.configuration Configuration for Redis&reg; replicas nodes
    ## ref: https://redis.io/topics/config
    ##
    configuration: ""
    disableCommands:
      - FLUSHALL
    ## @param replica.extraFlags Array with additional command line flags for Redis&reg; replicas
    ## e.g:
    extraFlags:
      - "--maxmemory 1024mb"
      - "--maxmemory-policy noeviction"
    ## @param replica.containerPorts.redis Container port to open on Redis&reg; replicas nodes
    ##
    containerPorts:
      redis: 6379
    persistence:
      enabled: true
      path: /data
      subPath: ""
      subPathExpr: ""
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 2Gi
    serviceAccount:
      create: false

secor:
  enabled: true
  namespace: secor

  # common variables used across all jobs
  extractor_timestamp_key: &extractor-timestamp-key "syncts"
  default_timestamp_key: &default-timestamp-key "obsrv_meta.syncts"
  fallback_timestamp_key: &fallback-timestamp-key "ets"
  # kafka_broker_host: &kafka-broker-host "obsrv-kafka-headless.kafka.svc.cluster.local"
  # zookeeper_quorum: &zookeeper-quorum "kafka-zookeeper-headless.kafka.svc.cluster.local:2181"
  file_size: &file-size "100000000"
  file_age: &file-age "100"
  backup_pv_size: &backup-pv-size "1Gi"
  request_cpu: &request-cpu "128m"
  request_memory: &request-memory "512Mi"
  secor_cpu_limit: &secor-cpu-limit "128m"
  secor_memory_limit: &secor-memory-limit "512Mi"
  threads: &threads 2

  # cloud_store_provider: "azure"
  # cloud_storage_bucket: *azure-container
  # azure_account: *azure-account-name
  # azure_secret: *azure-account-key
  cloud_store_provider: *global-cloud-storage-provider
  {{- if eq .Values.cloud_store_provider "azure" }}
  upload_manager: "com.pinterest.secor.uploader.AzureUploadManager"
  {{- else if eq .Values.cloud_store_provider "s3" }}
  upload_manager: "com.pinterest.secor.uploader.S3UploadManager"
  {{- else if eq .Values.cloud_store_provider "gcs" }}
  upload_manager: "com.pinterest.secor.uploader.GcsUploadManager"
  {{- end }}
  storageClass: *global-k9s-storage-class
  secor_env: *global-env
  region: *global-region
  image_repository: "sanketikahub/secor"
  pullPolicy: "IfNotPresent"
  image_tag: "1.0.0-GA"
  jvm_memory: "1024m"
  timezone: "UTC"
  # message_timezone: "UTC"
  # parser_timezone: "Asia/Kolkata"
  secor_jobs:
    ingest-backup:
      replicas: 1
      consumer_group: "dev_ingest"
      service_name: "ingest-backup"
      base_path: "telemetry-data/ingest"
      timestamp_key: *extractor-timestamp-key
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.ingest"
      # kafka_broker_host: *kafka-broker-host
      # zookeeper_quorum: *zookeeper-quorum
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: "dataset"
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.ChannelDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

    raw-backup:
      replicas: 1
      consumer_group: "dev_raw"
      service_name: "raw"
      base_path: "telemetry-data/raw"
      timestamp_key: *default-timestamp-key
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.raw"
      # kafka_broker_host: *kafka-broker-host
      # zookeeper_quorum: *zookeeper-quorum
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: "dataset"
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.ChannelDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

    failed-backup:
      replicas: 1
      consumer_group: "dev_failed"
      service_name: "failed"
      base_path: "telemetry-data/failed"
      timestamp_key: *default-timestamp-key
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.failed"
      # kafka_broker_host: *kafka-broker-host
      # zookeeper_quorum: *zookeeper-quorum
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: "dataset"
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.ChannelDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

    unique-backup:
      replicas: 1
      consumer_group: "dev_unique"
      service_name: "unique"
      base_path: "telemetry-data/unique"
      timestamp_key: *default-timestamp-key
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.unique"
      # kafka_broker_host: *kafka-broker-host
      # zookeeper_quorum: *zookeeper-quorum
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: "dataset"
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.ChannelDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

    denorm-backup:
      replicas: 1
      consumer_group: "dev_denorm"
      service_name: "denorm"
      base_path: "telemetry-data/denorm"
      timestamp_key: *default-timestamp-key
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.denorm"
      # kafka_broker_host: *kafka-broker-host
      # zookeeper_quorum: *zookeeper-quorum
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: "dataset"
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.ChannelDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

    transform-backup:
      replicas: 1
      consumer_group: "dev_transform"
      service_name: "transform"
      base_path: "telemetry-data/transformed"
      timestamp_key: *default-timestamp-key
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.transform"
      # kafka_broker_host: *kafka-broker-host
      # zookeeper_quorum: *zookeeper-quorum
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: "dataset"
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.ChannelDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

    system-events:
      replicas: 1
      consumer_group: "dev_system_events"
      service_name: "system-events"
      base_path: "telemetry-data/system-events"
      timestamp_key: "ets"
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.system.events"
      # kafka_broker_host: *kafka-broker-host
      # zookeeper_quorum: *zookeeper-quorum
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: "data.dataset"
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.ChannelDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

    system-telemetry-events:
      replicas: 1
      consumer_group: "dev_system_telemetry_events"
      service_name: "system-telemetry-events"
      base_path: "telemetry-data/system-telemetry-events"
      timestamp_key: "ets"
      fallback_timestamp_key: *fallback-timestamp-key
      topic: "dev.system.telemetry.events"
      # kafka_broker_host: "${kafka_broker_host}"
      # zookeeper_quorum: "${zookeeper_quorum}"
      max_file_size: *file-size
      max_file_age: *file-age
      partition_prefix_enabled: "false"
      partition_prefix_key: ""
      partition_prefix_mapping: "{}"
      message_channel_identifier: ""
      output_file_pattern: "{partition}-{currentTimestamp}.json"
      message_parser: "com.pinterest.secor.parser.PatternDateMessageParser"
      storage:
        size: *backup-pv-size
      requests:
        cpu: *request-cpu
        memory: *request-memory
      limits:
        cpu: *secor-cpu-limit
        memory: *secor-memory-limit
      lag_threshold_warning: 100000
      threads: *threads
      lag_threshold_critical: 200000

  alertrules:
    enabled: false

  describedobject:
    name: "data-path"

submit-ingestion:
  enabled: true
  namespace: submit-ingestion
  druid_router_host: "druid-raw-routers.druid-raw.svc.cluster.local"
  druid_router_port: 8888
  druid_indexer_host: "druid-raw-indexers.druid-raw.svc.cluster.local"
  druid_indexer_port: 8091
  datasource:
    system_events:
      topic: *sys-events-kafka-topic
      name: "system-events"
      segment_granularity: "day"
      query_granularity: "PT5M"
      task_duration: "PT1H"
      task_completion: "PT1H"
      task_count: 1
      replicas: 1
      enable: true
    system_telemetry_events:
      topic: *sys-telemetry-events-kafka-topic
      name: "system-telemetry-events"
      segment_granularity: "hour"
      query_granularity: "hour"
      task_duration: "PT1H"
      task_completion: "PT1H"
      task_count: 1
      replicas: 1
      enable: true

monitoring:
  enabled: true
  namespace: monitoring
  namespaceOverride: monitoring
  commonLabels:
    system.monitoring: 'true'
  alertmanager:
    alertmanagerSpec:
      podLabels:
        system.monitoring: 'true'
      resources:
        limits:
          cpu: 128m
          memory: 256Mi
        requests:
          cpu: 128m
          memory: 256Mi
  prometheusOperator:
    resources:
      limits:
        cpu: 200m
        memory: 200Mi
      requests:
        cpu: 100m
        memory: 100Mi
    prometheusConfigReloader:
      resources:
        limits:
          cpu: 200m
          memory: 50Mi
        requests:
          cpu: 200m
          memory: 50Mi
  kube-state-metrics:
    namespaceOverride: monitoring
    resources:
      limits:
        cpu: 100m
        memory: 64Mi
      requests:
        cpu: 10m
        memory: 32Mi
  grafana:
    namespaceOverride: monitoring
    extraLabels:
      system.monitoring: 'true'
    podLabels:
        system.monitoring: 'true'
    resources:
      limits:
        cpu: 0.2
        memory: 256Mi
      requests:
        cpu: 0.1
        memory: 128Mi
  prometheus:
    commonMetaLabels:
      system.monitoring: 'true'
    server:
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 500m
          memory: 512Mi
    prometheusSpec:
      retention: 90d
      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 10Gi
  prometheus-node-exporter:
    namespaceOverride: monitoring
    podLabels:
      system.monitoring: 'true'
    resources:
      limits:
        cpu: 100m
        memory: 64Mi
      requests:
        cpu: 100m
        memory: 32Mi

loki:
  enabled: true
  namespace: loki
  nameOverride: loki
  fullnameOverride: loki
  auth_enabled: false
  podLabels:
    system.monitoring: "true"
  commonConfig:
    replication_factor: 1
  limits_config:
    enforce_metric_name: false
    reject_old_samples: true
    reject_old_samples_max_age: "168h"
    max_cache_freshness_per_query: "10m"
    split_queries_by_interval: "15m"
    retention_period: "48h"
  storage:
    type: azure
  compactor:
    retention_enabled: true
    working_directory: /var/loki/compactor/retention
  test:
    enabled: false
  minio:
    enabled: true
    namespace: loki
    resources:
      limits:
        cpu: 0.1
        memory: 256Mi
      requests:
        cpu: 0.1
        memory: 256Mi
    metrics:
      serviceMonitor:
        enabled: true
        namespace: loki
        includeNode: true
        additionalLabels:
          release: monitoring
  grafana-agent-operator:
    namespace: loki
  monitoring:
    nameOverride: loki
    fullnameOverride: loki
    selfMonitoring:
      enabled: false
    dashboards:
      namespace: monitoring
    lokiCanary:
      enabled: false
      namespace: monitoring
      resources:
        limits:
          cpu: 0.1
          memory: 256Mi
        requests:
          cpu: 0.1
          memory: 128Mi
    serviceMonitor:
      labels:
        release: monitoring
        system.monitoring: "true"
  gateway:
    resources:
      limits:
        cpu: 0.1
        memory: 256Mi
      requests:
        cpu: 0.1
        memory: 128Mi
  read:
    #    affinity: {}
    replicas: 1
    podLabels:
      system.monitoring: 'true'
    resources:
      limits:
        cpu: 512m
        memory: 1024Mi
      requests:
        cpu: 256m
        memory: 512Mi
  write:
    #    affinity: {}
    replicas: 1
    podLabels:
      system.monitoring: 'true'
    resources:
      limits:
        cpu: 512m
        memory: 1024Mi
      requests:
        cpu: 256m
        memory: 512Mi

promtail:
  enabled: true
  namespace: loki
  resources:
    limits:
      cpu: 200m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  serviceMonitor:
    enabled: true
    labels:
      release: monitoring
      system.monitoring: "true"
  podLabels:
    system.monitoring: 'true'

web-console:
  enabled: true
  namespace: web-console
  service:
    type: NodePort